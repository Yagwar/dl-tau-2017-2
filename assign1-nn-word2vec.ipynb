{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "# COSC 7336"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Student Name:  \n",
    "\n",
    "The items 1 and 2 of the assignment must be completed in this notebook. Check that the notebook executes properly and that the corresponding outputs render appropriately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as pl\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. (1.25)\n",
    "Consider the following neural network:\n",
    "\n",
    "![title](nn.jpg)\n",
    "\n",
    "where $a_{i}=\\sum_{j}w_{j}^{i}z_{j}$ , $z_{i}=f_{i}(a_{i})$ for\n",
    "$i=1,2,3,4$, $z_{5}=a_{5}$ (an input neuron), $f_{2}(x)=\\textrm{relu}(x)$,\n",
    "and $f_{1}(x)=f_{3}(x)=f_{4}(x)=\\textrm{sigmoid}(x)$. $\\textrm{relu}(x)$\n",
    "corresponds to a rectifier linear unit transfer function defined as:\n",
    "$$\n",
    "\\textrm{relu}(x)=\\begin{cases}\n",
    "x & \\textrm{if }x\\ge0\\\\\n",
    "0 & \\textrm{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "1.a Write a function to simulate the neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagate(x, w):\n",
    "    '''\n",
    "    x: input value for neuron 5\n",
    "    w: weights array in the following order\n",
    "       [w13, w12, w14, w32, w42, w53, w54]\n",
    "    Returns: an array z with the output values for each\n",
    "             neuron\n",
    "    '''\n",
    "    z = np.zeros(5)\n",
    "    # your code here\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.b Deduce the equations to calculate $\\delta_{i}$ (the error value per\n",
    "neuron) for all the neurons. Write a function that given a training\n",
    "sample and the weights of the network calculate $\\delta_{i}$ for\n",
    "each neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bp(x, y, w):\n",
    "    '''\n",
    "    x: input value for neuron 5\n",
    "    y: output value for neuron 1\n",
    "    w: weights array in the following order\n",
    "       [w13, w12, w14, w32, w42, w53, w54]\n",
    "    Returns: an array delta with the delta values for each\n",
    "             neuron\n",
    "    '''\n",
    "    delta = np.zeros(5)\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.c Write a function to update the neural network weights when a new training sample is shown using stochastic gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_step(x, y, w, eta):\n",
    "    '''\n",
    "    x: input value for neuron 5\n",
    "    y: output value for neuron 1\n",
    "    w: weights array in the following order\n",
    "       [w13, w12, w14, w32, w42, w53, w54]\n",
    "    eta: learning rate\n",
    "    Returns: updated w array\n",
    "    '''\n",
    "    # Calculate dw\n",
    "    # Your code here\n",
    "    dw = np.zeros(5)\n",
    "    w = w - eta*dw\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.d Use the previous function to train the network with this [training samples](http://fagonzalezo.github.io/ml/samples_assign4.txt).  Plot the evolution of the error and the predictions of the trained network. Write down the weights of the trained network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2. Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download pretrained word embeddings from Google News dataset. The model includes embeddings for 3 million words and phrases. Words with frequency below 5 were discarded. Download the model from the link below: https://code.google.com/archive/p/word2vec/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model using gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gensim.models\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('..//..//GoogleNews.bin', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Write a function to find antonyms\n",
    "Given an input word w, the funtion find_antonynm(w) should return a list of possible antonyms. Test your function, find examples for which this function works and some for which it doesn't. Explain why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tall -\n",
      "easy -\n",
      "fast -\n",
      "happy -\n"
     ]
    }
   ],
   "source": [
    "def antonym(word):\n",
    "    ### Your code should go here\n",
    "    return '-'\n",
    "\n",
    "for word in ['tall', 'easy', 'fast', 'happy']:\n",
    "    print word, antonym(word)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Write a function to find the word that doesn't belong\n",
    "Gensim has a function doesnt_match that identifies the word that doesn't belong to the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Google'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(\"Google to acquire small start up\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acquiring\n",
      "[[u'acquiring', 1.0944626018517578], [u'aquire', 0.60038910849752047], [u'acquired', 1.102685877744592], [u'acquires', 0.99060256297243721], [u'acquisition', 1.1583006072460782], [u'reacquire', 0.59744085561553872], [u'purchase', 0.93053546164630252], [u'Acquire', 0.51988587567775035], [u'Acquiring', 0.62152500624361062], [u'buy', 0.82539057980610719]]\n",
      "[(u'acquiring', 0.7087349891662598), (u'aquire', 0.6920976638793945), (u'acquired', 0.6788821220397949), (u'acquires', 0.6195156574249268), (u'acquisition', 0.6143543720245361), (u'reacquire', 0.6086897253990173), (u'purchase', 0.601489782333374), (u'Acquire', 0.5971122980117798), (u'Acquiring', 0.5743354558944702), (u'buy', 0.5730166435241699)]\n"
     ]
    }
   ],
   "source": [
    "#model.most_similar(negative=['Regan'], positive=['Obama', 'Bush', 'Clinton'])\n",
    "l =model.most_similar(positive=['acquire'], topn=10)\n",
    "print l[0][0]\n",
    "#type(list[0])\n",
    "sim_w=[]\n",
    "for w in range(len(l)):\n",
    "    sim_w.append([l[w][0],0])\n",
    "    #print sim_w[w][0]\n",
    "    #print l[w][0]\n",
    "    for words in [\"Google\", \"small\", \"startup\", \"announced\", \"million\", \"corporation\", \"opportunities\"]:\n",
    "        #print words\n",
    "        #sim_w[w].append([])\n",
    "        sim_w[w][1]= sim_w[w][1] + model.similarity(words, l[w][0])\n",
    "print sim_w\n",
    "print l\n",
    "#model.wv.most_similar_cosmul(positive=['Google','acquire','small', 'startup'], topn=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task is to implement a new function that does the same job. Test it with different lists and compare agianst the gensim function. Explain why your function works on some lists but not others.\n",
    "### Note: \n",
    "You're only allowed to use the predifined function similarity for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def this_word_doesnt_belong(word_list):\n",
    "    ### Your code goes here\n",
    "    return '-'\n",
    "\n",
    "print this_word_doesnt_belong(\"Obama Clinton Bush Reagan Bieber\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Write a function for lexical substitution\n",
    "Lexical substitution is the task of finding alternative words that preserve the meaning of the sentence. An example task where lexical substitution is relevant is text simplification. There has been work on using embeddings to solve this task. Write a new function that suggests a lexical substitute for a word given the context provided. You can assume that the oringal list is a sentence, or simply a list of words. In the example below we would expect your function to return an n-best list of candidate words (n<=10) where words like \"purchase\" and \"buy\" appear, ideally in the top places.\n",
    "Make sure you plan to handle Out of Vocabulary Words (OOV). Here it's okay to just ignore from the context any OOV words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def lexical_substitute(word_context, target):\n",
    "    ### Your code goes here\n",
    "    #Somewhere here you should have a call to this_word_doesnt_belong\n",
    "    return '-'\n",
    "\n",
    "print lexical_substitute(\"Google acquires small start up behind Fabby selfy apps\", \"acquires\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
